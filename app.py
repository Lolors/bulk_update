import streamlit as st
import pandas as pd
from datetime import datetime
from openpyxl import load_workbook
from openpyxl.utils import (
    column_index_from_string,
    get_column_letter,
    range_boundaries,
)
from io import BytesIO
import re
import zipfile


# =========================================================
# ê³µí†µ ìœ í‹¸
# =========================================================
def read_csv_flexible(uploaded_file):
    """
    Streamlit ì—…ë¡œë“œëœ CSV íŒŒì¼ì„ ì¸ì½”ë”©/êµ¬ë¶„ì ìë™ íƒì§€í•´ì„œ ì½ê¸°.
    """
    if uploaded_file is None:
        raise ValueError("CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    encodings = ["cp949", "utf-8-sig", "utf-8", "ansi", "utf-16"]

    for enc in encodings:
        try:
            uploaded_file.seek(0)
            df = pd.read_csv(uploaded_file, encoding=enc)
            if df.columns.size > 0:
                return df
        except Exception:
            continue

    # êµ¬ë¶„ì ìë™ ì¶”ì¸¡
    try:
        uploaded_file.seek(0)
        df = pd.read_csv(uploaded_file, sep=None, engine="python")
        if df.columns.size > 0:
            return df
    except Exception:
        pass

    raise ValueError("CSV íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì¸ì½”ë”©/êµ¬ë¶„ì ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.)")


def adjust_formula_row(formula: str, old_row: int, new_row: int) -> str:
    """
    ìˆ˜ì‹ ë¬¸ìì—´ì—ì„œ ì…€ ì£¼ì†Œì˜ 'í–‰ ë²ˆí˜¸'ë§Œ old_row -> new_row ë¡œ ë°”ê¾¼ë‹¤.
    ì˜ˆ) =($R418+[@ì™¸ì£¼ìˆ˜ëŸ‰])-$T418  â†’ =($R419+[@ì™¸ì£¼ìˆ˜ëŸ‰])-$T419

    êµ¬ì¡°í™” ì°¸ì¡°([@ì™¸ì£¼ìˆ˜ëŸ‰], í‘œ1[@ì™¸ì£¼ìˆ˜ëŸ‰]) ê°™ì€ ê±´ ê±´ë“œë¦¬ì§€ ì•ŠëŠ”ë‹¤.
    """
    if not isinstance(formula, str) or not formula.startswith("="):
        return formula

    # ì…€ì£¼ì†Œ íŒ¨í„´ë§Œ ì¡ê¸°: $ + A~Z 1~3ê¸€ì + old_row + ë‹¨ì–´ ê²½ê³„
    pattern = re.compile(rf'(\$?[A-Z]{{1,3}}){old_row}\b')

    def repl(m):
        col = m.group(1)
        return f"{col}{new_row}"

    return pattern.sub(repl, formula)


# =========================================================
# ë©”ì¸ ì‹œíŠ¸ í–‰/ì—´ ê´€ë ¨ ìœ í‹¸ (ì—…ë°ì´íŠ¸ íƒ­)
# =========================================================
def find_main_row(ws_main, part_no, lot_no):
    """
    ë©”ì¸ ì‹œíŠ¸ì—ì„œ í’ˆëª©ì½”ë“œ(B), ë¡œíŠ¸ë²ˆí˜¸(D)ê°€ ì¼ì¹˜í•˜ëŠ” í–‰ì„ ì°¾ëŠ”ë‹¤.
    ì—†ìœ¼ë©´ 0 ë¦¬í„´.
    ë°ì´í„°ëŠ” 3í–‰ë¶€í„° ì‹œì‘í•œë‹¤ê³  ê°€ì •.
    """
    max_row = ws_main.max_row
    for r in range(3, max_row + 1):
        v_part = str(ws_main.cell(row=r, column=2).value or "").strip()  # Bì—´
        v_lot = str(ws_main.cell(row=r, column=4).value or "").strip()   # Dì—´
        if v_part == str(part_no).strip() and v_lot == str(lot_no).strip():
            return r
    return 0


def get_template_row(ws_main):
    """
    ë§¨ ì•„ë˜ì—ì„œ ìœ„ë¡œ ì˜¬ë¼ê°€ë©´ì„œ ë¡œíŠ¸ë²ˆí˜¸(Dì—´)ê°€ ë¹„ì–´ìˆì§€ ì•Šì€ í–‰ì„
    í…œí”Œë¦¿ í–‰ìœ¼ë¡œ ì‚¬ìš©.
    """
    for r in range(ws_main.max_row, 2, -1):
        v_lot = str(ws_main.cell(row=r, column=4).value or "").strip()
        if v_lot != "":
            return r
    return None


def get_drum_col_letters():
    """
    VBA ë§¤í•‘ ê·¸ëŒ€ë¡œ: X:CE êµ¬ê°„ì—ì„œ (ìš©ëŸ‰, ìœ„ì¹˜, ë³´ìœ í†µ) Ã— 20
      1ë²ˆ: (X,Y,Z)
      2ë²ˆ: (AA,AB,AC)
      ...
      20ë²ˆ: (CC,CD,CE)
    """
    qtyCols = {
        1: "X",  2: "AA", 3: "AD", 4: "AG", 5: "AJ",
        6: "AM", 7: "AP", 8: "AS", 9: "AV", 10: "AY",
        11: "BB", 12: "BE", 13: "BH", 14: "BK", 15: "BN",
        16: "BQ", 17: "BT", 18: "BW", 19: "BZ", 20: "CC",
    }
    locCols = {
        1: "Y",  2: "AB", 3: "AE", 4: "AH", 5: "AK",
        6: "AN", 7: "AQ", 8: "AT", 9: "AW", 10: "AZ",
        11: "BC", 12: "BF", 13: "BI", 14: "BL", 15: "BO",
        16: "BR", 17: "BU", 18: "BX", 19: "CA", 20: "CD",
    }
    stockCols = {
        1: "Z",  2: "AC", 3: "AF", 4: "AI", 5: "AL",
        6: "AO", 7: "AR", 8: "AU", 9: "AX", 10: "BA",
        11: "BD", 12: "BG", 13: "BJ", 14: "BM", 15: "BP",
        16: "BS", 17: "BV", 18: "BY", 19: "CB", 20: "CE",
    }
    return qtyCols, locCols, stockCols


# =========================================================
# í…Œì´ë¸”(í‘œ1 ë“±) ë²”ìœ„ í™•ì¥ (ì—…ë°ì´íŠ¸ íƒ­)
# =========================================================
def extend_tables_for_new_row(ws, template_row, new_row):
    """
    template_row ë¥¼ í¬í•¨í•˜ëŠ” ëª¨ë“  í…Œì´ë¸”ì˜ ref ë²”ìœ„ë¥¼
    new_row ê¹Œì§€ ì•„ë˜ë¡œ í™•ì¥í•œë‹¤.
    (ê·¸ë˜ì•¼ ìƒˆ í–‰ë„ í‘œ ì•ˆì— ë“¤ì–´ê°€ê³ , [@ì™¸ì£¼ìˆ˜ëŸ‰] ê°™ì€ êµ¬ì¡°í™” ì°¸ì¡°ê°€ ì •ìƒ ì‘ë™)
    """
    try:
        tables = ws.tables.values()  # openpyxl 3.x
    except AttributeError:
        tables = ws._tables          # ì˜ˆì „ ë²„ì „ fallback

    for tbl in tables:
        ref = tbl.ref  # ì˜ˆ: 'F3:U418'
        min_col, min_row, max_col, max_row = range_boundaries(ref)

        if min_row <= template_row <= max_row:
            if new_row > max_row:
                new_ref = (
                    f"{get_column_letter(min_col)}{min_row}:"
                    f"{get_column_letter(max_col)}{new_row}"
                )
                tbl.ref = new_ref


# =========================================================
# í†µ ì—…ë°ì´íŠ¸ (VBA ApplyDrumUpdate í•µì‹¬, ì—…ë°ì´íŠ¸ íƒ­)
# =========================================================
def apply_drum_update_to_main(ws_main, row, drum_no, new_qty, new_loc):
    qtyCols, locCols, stockCols = get_drum_col_letters()

    if drum_no < 1 or drum_no > 20:
        st.warning(f"[ê²½ê³ ] í†µë²ˆí˜¸ {drum_no} ëŠ” 1~20 ë²”ìœ„ë¥¼ ë²—ì–´ë‚¨. ìŠ¤í‚µ.")
        return

    q_col_letter = qtyCols[drum_no]
    l_col_letter = locCols[drum_no]
    s_col_letter = stockCols[drum_no]

    q_col = column_index_from_string(q_col_letter)
    l_col = column_index_from_string(l_col_letter)
    s_col = column_index_from_string(s_col_letter)

    # ìƒˆ ìœ„ì¹˜/ìš©ëŸ‰ ì…ë ¥
    ws_main.cell(row=row, column=l_col, value=new_loc)

    loc_upper = str(new_loc or "").strip().upper()
    new_qty_val = float(new_qty or 0)

    if loc_upper in ("ì†Œì§„", "íê¸°"):
        ws_main.cell(row=row, column=s_col, value=0)        # ë³´ìœ í†µ
        ws_main.cell(row=row, column=q_col, value=0)        # ìš©ëŸ‰ë„ 0
    elif loc_upper == "ì™¸ì£¼":
        ws_main.cell(row=row, column=s_col, value=0)        # ë³´ìœ í†µ 0
        ws_main.cell(row=row, column=q_col, value=new_qty_val)
    else:
        ws_main.cell(row=row, column=q_col, value=new_qty_val)
        ws_main.cell(row=row, column=s_col, value=0 if new_qty_val == 0 else 1)


# =========================================================
# LOG ì‹œíŠ¸ í•œì¤„ ì¶”ê°€ (ì—…ë°ì´íŠ¸ íƒ­)
# =========================================================
def append_log_row(ws_log, log_row):
    """
    LOG ì‹œíŠ¸ì— í•œ ì¤„ ì¶”ê°€.
    - í—¤ë”ë¥¼ ë³´ê³  ì»¬ëŸ¼ ìœ„ì¹˜ë¥¼ ìë™ ì¸ì‹ (ID ìœ ë¬´ ìë™ ëŒ€ì‘)
    - CSV(log_row)ê°€ IDë¥¼ ê°€ì§€ê³  ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ê¸°ë¡
    - CSVì— IDê°€ ì—†ìœ¼ë©´ ë¹ˆì¹¸(ë˜ëŠ” None)ìœ¼ë¡œ ë‘ 
    """

    # 1) í—¤ë” ì½ì–´ì„œ "í—¤ë”ëª… -> ì—´ë²ˆí˜¸" ë§µ ìƒì„±
    header_map = {}
    max_col = ws_log.max_column
    for c in range(1, max_col + 1):
        hv = ws_log.cell(row=1, column=c).value
        if hv is None:
            continue
        header_map[str(hv).strip()] = c

    # 2) ìƒˆ í–‰ ìœ„ì¹˜
    last = ws_log.max_row
    if last < 1:
        last = 1
    new_r = last + 1

    # 3) ì„œì‹ ë³µì‚¬(ê°€ëŠ¥í•œ ë²”ìœ„ë§Œ)
    src_row = last
    for c in range(1, max_col + 1):
        src_cell = ws_log.cell(row=src_row, column=c)
        dst_cell = ws_log.cell(row=new_r, column=c)
        dst_cell._style = src_cell._style

    # 4) ê°’ ì±„ìš°ê¸° (CSV ì»¬ëŸ¼ëª…ê³¼ LOG í—¤ë”ëª…ì„ ë§¤ì¹­)
    # CSVìª½ í‚¤: ì‹œê°„, ID, í’ˆë²ˆ, í’ˆëª…, ë¡œíŠ¸ë²ˆí˜¸, í†µë²ˆí˜¸, ë³€ê²½ ì „ ìš©ëŸ‰, ë³€ê²½ í›„ ìš©ëŸ‰, ë³€í™”ëŸ‰, ë³€ê²½ ì „ ìœ„ì¹˜, ë³€ê²½ í›„ ìœ„ì¹˜
    value_map = {
        "ì‹œê°„": log_row.get("ì‹œê°„"),
        "ID": log_row.get("ID"),
        "í’ˆëª©ì½”ë“œ": log_row.get("í’ˆë²ˆ"),   # ì—‘ì…€ ë§¤í¬ë¡œ í—¤ë”ê°€ "í’ˆëª©ì½”ë“œ"ì¸ ê²½ìš°ë„ ëŒ€ì‘
        "í’ˆë²ˆ": log_row.get("í’ˆë²ˆ"),
        "í’ˆëª…": log_row.get("í’ˆëª…"),
        "ë¡œíŠ¸ë²ˆí˜¸": log_row.get("ë¡œíŠ¸ë²ˆí˜¸"),
        "í†µë²ˆí˜¸": log_row.get("í†µë²ˆí˜¸"),
        "ë³€ê²½ ì „ ìš©ëŸ‰": log_row.get("ë³€ê²½ ì „ ìš©ëŸ‰"),
        "ë³€ê²½ í›„ ìš©ëŸ‰": log_row.get("ë³€ê²½ í›„ ìš©ëŸ‰"),
        "ë³€í™”ëŸ‰": log_row.get("ë³€í™”ëŸ‰"),
        "ë³€ê²½ ì „ ìœ„ì¹˜": log_row.get("ë³€ê²½ ì „ ìœ„ì¹˜"),
        "ë³€ê²½ í›„ ìœ„ì¹˜": log_row.get("ë³€ê²½ í›„ ìœ„ì¹˜"),
    }

    for hdr, val in value_map.items():
        if hdr in header_map:
            ws_log.cell(row=new_r, column=header_map[hdr], value=val)

# =========================================================
# bulk_drums_extended ë©”íƒ€ êµ¬ì¶• (ì—…ë°ì´íŠ¸ íƒ­)
# =========================================================
def build_meta_from_extended(file_extended):
    """
    bulk_drums_extended.csv í—¤ë”:
    í’ˆëª©ì½”ë“œ, í’ˆëª…, ë¡œíŠ¸ë²ˆí˜¸, ì œí’ˆë¼ì¸, ì œì¡°ì¼ì, ìƒíƒœ, í†µë²ˆí˜¸, í†µìš©ëŸ‰, í˜„ì¬ìœ„ì¹˜
    (í’ˆëª©ì½”ë“œ, ë¡œíŠ¸ë²ˆí˜¸) ë³„ë¡œ ë©”íƒ€ ì •ë³´ ìƒì„±
    """
    df_ext = read_csv_flexible(file_extended)

    if "ì œì¡°ì¼ì" in df_ext.columns:
        df_ext["ì œì¡°ì¼ì"] = pd.to_datetime(df_ext["ì œì¡°ì¼ì"], errors="coerce")

    meta = {}
    grouped = df_ext.groupby(["í’ˆëª©ì½”ë“œ", "ë¡œíŠ¸ë²ˆí˜¸"], dropna=False)

    for (part, lot), grp in grouped:
        part_str = str(part).strip()
        lot_str = str(lot).strip()

        # ì œí’ˆë¼ì¸
        product_line_series = grp["ì œí’ˆë¼ì¸"].dropna().astype(str)
        product_line = product_line_series.iloc[0] if not product_line_series.empty else ""

        # ì œì¡°ì¼ì
        mfg = grp["ì œì¡°ì¼ì"].dropna()
        mfg_date = mfg.iloc[0] if not mfg.empty else None

        # ì „ì²´í†µìˆ˜ = í†µë²ˆí˜¸ ê³ ìœ  ê°œìˆ˜
        total_drums = grp["í†µë²ˆí˜¸"].nunique()

        # í’ˆëª…
        name_series = grp["í’ˆëª…"].dropna().astype(str)
        name_val = name_series.iloc[0] if not name_series.empty else ""

        meta[(part_str, lot_str)] = {
            "ì œí’ˆë¼ì¸": product_line,
            "ì œì¡°ì¼ì": mfg_date,
            "ì „ì²´í†µìˆ˜": total_drums,
            "í’ˆëª…": name_val,
        }

    return meta


# =========================================================
# ì‹ ê·œ ë¡œíŠ¸ í–‰ ìƒì„± (ì—…ë°ì´íŠ¸ íƒ­)
# =========================================================
def create_new_main_row(ws_main, part_no, lot_no, prod_name, meta_map, template_row):
    """
    ë©”ì¸ ì‹œíŠ¸ì— ì‹ ê·œ ë¡œíŠ¸ í–‰ ì¶”ê°€.
    - B: í’ˆëª©ì½”ë“œ(=í’ˆë²ˆ)
    - C: í’ˆëª…
    - D: ë¡œíŠ¸ë²ˆí˜¸
    - E: ì œí’ˆë¼ì¸ (meta)
    - G: ì œì¡°ì¼ì (meta)
    - W: ì „ì²´í†µìˆ˜ (meta)
    - F,H,I,N,O,P,R,S,T,U,V : í…œí”Œë¦¿ í–‰ ìˆ˜ì‹ì„ ë³µì‚¬í•˜ë˜, í–‰ ë²ˆí˜¸ë§Œ old->new êµì²´
    - ì „ì²´ í–‰ì— ëŒ€í•´ì„œ "ìœ„ í–‰" ìŠ¤íƒ€ì¼ ë³µì‚¬
    - ìƒˆ í–‰ì´ ë“¤ì–´ê°€ëŠ” ë§Œí¼ ê´€ë ¨ í…Œì´ë¸”(ref)ë„ ì•„ë˜ë¡œ í™•ì¥
    """

    key = (str(part_no).strip(), str(lot_no).strip())
    meta = meta_map.get(key, {})

    new_row = ws_main.max_row + 1

    # 0) ê´€ë ¨ í…Œì´ë¸” ë²”ìœ„ë¥¼ new_rowê¹Œì§€ í™•ì¥
    if template_row is not None:
        extend_tables_for_new_row(ws_main, template_row, new_row)

    # 1) ìœ„ í–‰(ë˜ëŠ” í…œí”Œë¦¿ í–‰)ì˜ ì„œì‹ì„ ìƒˆ í–‰ì— ì „ì²´ ë³µì‚¬
    base_row = template_row if template_row else new_row - 1
    max_col = ws_main.max_column

    for c in range(1, max_col + 1):
        src = ws_main.cell(row=base_row, column=c)
        dst = ws_main.cell(row=new_row, column=c)
        dst._style = src._style

    # 2) B,C,D,E,G,W ê°’ ì±„ìš°ê¸°
    ws_main[f"B{new_row}"] = str(part_no).strip()
    ws_main[f"C{new_row}"] = prod_name if prod_name else meta.get("í’ˆëª…", "")
    ws_main[f"D{new_row}"] = str(lot_no).strip()
    ws_main[f"E{new_row}"] = meta.get("ì œí’ˆë¼ì¸", "")
    ws_main[f"G{new_row}"] = meta.get("ì œì¡°ì¼ì", None)
    ws_main[f"W{new_row}"] = meta.get("ì „ì²´í†µìˆ˜", None)

    # 3) F,H,I,N,O,P,R,S,T,U,V ìˆ˜ì‹/ê°’ ë³µì‚¬ + í–‰ ë²ˆí˜¸ ì¹˜í™˜
    formula_cols = ["F", "H", "I", "N", "O", "P", "R", "S", "T", "U", "V"]

    if template_row is not None:
        for col in formula_cols:
            src = ws_main[f"{col}{template_row}"]
            dst = ws_main[f"{col}{new_row}"]

            val = src.value

            if isinstance(val, str) and val.startswith("="):
                dst.value = adjust_formula_row(val, template_row, new_row)
            else:
                dst.value = val

    return new_row


# =========================================================
# ë©”ì¸ ì²˜ë¦¬ (ì—…ë°ì´íŠ¸ íƒ­)
# =========================================================
def process_bulk_log_streamlit(excel_file, bulk_log_file, bulk_ext_file):
    """
    ì—…ë¡œë“œëœ íŒŒì¼ ê°ì²´ 3ê°œë¥¼ ë°›ì•„ì„œ
    ì—‘ì…€(ë©”ì¸+LOG)ì— ë¡œê·¸ ë°˜ì˜ í›„ BytesIO ë¡œ ë°˜í™˜
    """
    # 0) extended ë©”íƒ€ ì¤€ë¹„
    meta_map = build_meta_from_extended(bulk_ext_file)

    # 1) ì—‘ì…€ ë¡œë“œ (ë§¤í¬ë¡œ ìœ ì§€)
    excel_bytes = excel_file.read()
    wb = load_workbook(BytesIO(excel_bytes), keep_vba=True)

    if "ë©”ì¸" not in wb.sheetnames or "LOG" not in wb.sheetnames:
        raise ValueError("ì—‘ì…€ íŒŒì¼ì— 'ë©”ì¸' ë˜ëŠ” 'LOG' ì‹œíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

    ws_main = wb["ë©”ì¸"]
    ws_log = wb["LOG"]

    template_row = get_template_row(ws_main)

    # 2) LOG ì‹œíŠ¸ì—ì„œ ê¸°ì¡´ ë§ˆì§€ë§‰ ì‹œê°„ ì½ê¸°
    log_times = []
    for r in range(2, ws_log.max_row + 1):
        val = ws_log.cell(row=r, column=1).value
        if isinstance(val, datetime):
            log_times.append(val)
    last_time = max(log_times) if log_times else datetime.min

    # 3) bulk_move_log ì½ê¸°
    df_log = read_csv_flexible(bulk_log_file)

    # í•„ìˆ˜ ì»¬ëŸ¼ ì²´í¬
    required_cols = [
        "ì‹œê°„", "í’ˆë²ˆ", "í’ˆëª…", "ë¡œíŠ¸ë²ˆí˜¸", "í†µë²ˆí˜¸",
        "ë³€ê²½ ì „ ìš©ëŸ‰", "ë³€ê²½ í›„ ìš©ëŸ‰", "ë³€í™”ëŸ‰",
        "ë³€ê²½ ì „ ìœ„ì¹˜", "ë³€ê²½ í›„ ìœ„ì¹˜",
    ]

    # í•„ìˆ˜ ì»¬ëŸ¼ ì²´í¬
    for col in required_cols:
        if col not in df_log.columns:
            raise ValueError(f"bulk_move_log.csv ì— '{col}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    # ID ì»¬ëŸ¼ì€ ì„ íƒ (ì—†ìœ¼ë©´ ìë™ ìƒì„±)
    if "ID" not in df_log.columns:
        df_log["ID"] = None

    df_log["ì‹œê°„"] = pd.to_datetime(df_log["ì‹œê°„"], errors="coerce")

    # 4) ì‹ ê·œ ë¡œê·¸ë§Œ í•„í„° + ì •ë ¬
    new_logs = df_log[df_log["ì‹œê°„"] > last_time].copy()
    new_logs = new_logs.sort_values("ì‹œê°„")

    if new_logs.empty:
        st.info("ë°˜ì˜í•  ì‹ ê·œ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤. (bulk_move_log.csv ê¸°ì¤€)")
        out = BytesIO()
        wb.save(out)
        out.seek(0)
        return out, 0

    # 5) ì‹ ê·œ ë¡œê·¸ í•œ ì¤„ì”© ë°˜ì˜
    applied_count = 0
    for _, row in new_logs.iterrows():
        part_no = str(row["í’ˆë²ˆ"]).strip()
        lot_no = str(row["ë¡œíŠ¸ë²ˆí˜¸"]).strip()
        prod_name = str(row.get("í’ˆëª…", "") or "").strip()
        drum_no = int(row["í†µë²ˆí˜¸"])
        new_qty = row["ë³€ê²½ í›„ ìš©ëŸ‰"]
        new_loc = str(row["ë³€ê²½ í›„ ìœ„ì¹˜"])

        main_row = find_main_row(ws_main, part_no, lot_no)

        if main_row == 0:
            st.write(f"[ì‹ ê·œ ë¡œíŠ¸ ìƒì„±] í’ˆë²ˆ={part_no}, ë¡œíŠ¸={lot_no}")
            main_row = create_new_main_row(
                ws_main,
                part_no=part_no,
                lot_no=lot_no,
                prod_name=prod_name,
                meta_map=meta_map,
                template_row=template_row,
            )
            template_row = main_row

        apply_drum_update_to_main(ws_main, main_row, drum_no, new_qty, new_loc)
        append_log_row(ws_log, row.to_dict())
        applied_count += 1

    # 6) ê²°ê³¼ë¥¼ BytesIO ë¡œ ë°˜í™˜
    out = BytesIO()
    wb.save(out)
    out.seek(0)
    return out, applied_count


# =========================================================
# ì¶”ì¶œ íƒ­: ë©”ì¸ ì‹œíŠ¸ â†’ bulk_drums_extended.csv
# (ê¸°ì¡´ app.py ë¡œì§ ê¸°ë°˜)
# =========================================================
def extract_bulk_drums_from_main(excel_bytes: bytes, sheet_name: str = "ë©”ì¸") -> pd.DataFrame:
    """
    ë©”ì¸ ì—‘ì…€ ì‹œíŠ¸ì—ì„œ bulk_drums_extended í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œ.

    ê·œì¹™:
    1) ì„¸ë¶€ìœ„ì¹˜(CF~CY)ê°€ ìˆìœ¼ë©´ -> í˜„ì¬ìœ„ì¹˜ = ì„¸ë¶€ìœ„ì¹˜
    2) ì„¸ë¶€ìœ„ì¹˜ê°€ ì—†ìœ¼ë©´ -> ë©”ì¸ ìœ„ì¹˜(ì¸µ) ë³´ê³ 
       - ì™¸ì£¼/íê¸°/ì†Œì§„: ê·¸ëŒ€ë¡œ
       - ê·¸ ì™¸: "Xì¸µ ë³´ê´€" ìœ¼ë¡œ ê°•ì œ
    """

    # (A) pandasë¡œ ê¸°ë³¸ ë°ì´í„°(í’ˆëª©/ë¡œíŠ¸/í†µìš©ëŸ‰/ì¸µ/ë³´ìœ í†µ ë“±) ì½ê¸°
    df = pd.read_excel(BytesIO(excel_bytes), sheet_name=sheet_name, header=1)

    if "1ë²ˆ" not in df.columns:
        raise ValueError(f'"{sheet_name}" ì‹œíŠ¸ì—ì„œ "1ë²ˆ" ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.')

    start_idx = df.columns.get_loc("1ë²ˆ")

    # (B) openpyxlë¡œ ì„¸ë¶€ìœ„ì¹˜(CF~CY) ì½ê¸°
    wb = load_workbook(BytesIO(excel_bytes), data_only=True)
    ws = wb[sheet_name]

    detail_cols = {
        1: "CF", 2: "CG", 3: "CH", 4: "CI", 5: "CJ",
        6: "CK", 7: "CL", 8: "CM", 9: "CN", 10: "CO",
        11: "CP", 12: "CQ", 13: "CR", 14: "CS", 15: "CT",
        16: "CU", 17: "CV", 18: "CW", 19: "CX", 20: "CY",
    }

    def norm_str(v) -> str:
        if v is None:
            return ""
        if isinstance(v, float) and pd.isna(v):
            return ""
        s = str(v).strip()
        return s

    def to_floor_str(floor_raw: str) -> str:
        """
        '4' -> '4ì¸µ'
        '4ì¸µ' -> '4ì¸µ'
        '4ì¸µ ë³´ê´€' -> '4ì¸µ'
        'ì°½ê³  ë³´ê´€' -> 'ì°½ê³ '
        """
        s = norm_str(floor_raw)
        if not s:
            return ""
        # âœ… íŠ¹ìˆ˜ êµ¬ì—­ì€ ë’¤ í…ìŠ¤íŠ¸ê°€ ë¶™ì–´ë„ ê·¸ëŒ€ë¡œ ìœ ì§€ (ì˜ˆ: 'ì°½ê³  ë³´ê´€' â†’ 'ì°½ê³ ')
        for special in ("ì™¸ì£¼", "íê¸°", "ì†Œì§„", "ì°½ê³ "):
            if s == special or s.startswith(f"{special} ") or s.startswith(f"{special}_") or s.startswith(f"{special}-"):
                return special
        if re.fullmatch(r"\d+", s):
            return f"{s}ì¸µ"
        m = re.search(r"(\d+ì¸µ)", s)
        return m.group(1) if m else ""

    rows = []

    # DataFrameì˜ ì²« í–‰(index 0) = ì—‘ì…€ 3í–‰ (1í–‰ ì œëª©, 2í–‰ í—¤ë”ë¼ëŠ” ì „ì œ)
    for excel_row, (_, row) in enumerate(df.iterrows(), start=3):

        part = row.get("í’ˆëª©ì½”ë“œ")
        name = row.get("í’ˆëª…")

        # í’ˆëª© ì •ë³´ ì—†ìœ¼ë©´ ìŠ¤í‚µ
        if (pd.isna(part) or norm_str(part) == "") and (pd.isna(name) or norm_str(name) == ""):
            continue

        base = {
            "í’ˆëª©ì½”ë“œ": norm_str(part),
            "í’ˆëª…": norm_str(name),
            "ë¡œíŠ¸ë²ˆí˜¸": norm_str(row.get("ë¡œíŠ¸ë²ˆí˜¸")),
            "ì œí’ˆë¼ì¸": norm_str(row.get("ì œí’ˆë¼ì¸")),
            "ì œì¡°ì¼ì": pd.to_datetime(row.get("ì œì¡°ì¼ì")).date()
                        if not pd.isna(row.get("ì œì¡°ì¼ì")) else pd.NaT,
            "ìƒíƒœ": norm_str(row.get("ìƒíƒœ")),
        }

        for drum_no in range(1, 21):
            cap_col = start_idx + 3 * (drum_no - 1)      # í†µìš©ëŸ‰
            loc_col = start_idx + 3 * (drum_no - 1) + 1  # ìœ„ì¹˜(ì¸µ)
            cnt_col = start_idx + 3 * (drum_no - 1) + 2  # ë³´ìœ í†µ

            cap = row.iloc[cap_col]
            floor_raw = row.iloc[loc_col]
            cnt_raw = row.iloc[cnt_col]

            # 1) ì„¸ë¶€ìœ„ì¹˜(ìˆ¨ê¹€ì—´) ë¨¼ì € ì½ê¸°
            detail_cell = f"{detail_cols[drum_no]}{excel_row}"
            detail_val = norm_str(ws[detail_cell].value)

            # âœ… ì •ê·œí™”: ì„¸ë¶€ìœ„ì¹˜ì— 'nì¸µ ë³´ê´€' ê°™ì€ ê°’ì´ ë“¤ì–´ì˜¤ë©´
            #    "ì„¸ë¶€ìœ„ì¹˜ê°€ ìˆëŠ” ê²ƒ"ìœ¼ë¡œ ë³´ì§€ ì•Šê³ , ì¸µ ê¸°ë°˜ ë¡œì§ìœ¼ë¡œ ë³´ë‚´ê¸°
            if detail_val:
                # 'ë³´ê´€'ì´ ì¤‘ë³µëœ ê²½ìš°(ë³´ê´€ ë³´ê´€) 1ê°œë¡œ ì¶•ì•½
                detail_val = re.sub(r"(ë³´ê´€)(\s+\1)+", r"\1", detail_val).strip()

                # ì„¸ë¶€ìœ„ì¹˜ê°€ ì‚¬ì‹¤ìƒ ì—†ë‹¤ëŠ” ì˜ë¯¸ì˜ ê°’ë“¤ì€ ë¹„ì›Œì„œ(=ì¸µ ê¸°ì¤€ ì²˜ë¦¬)
            # 2) í˜„ì¬ìœ„ì¹˜ ê²°ì •
            floor = to_floor_str(floor_raw)
            detail = norm_str(detail_val)

            # ğŸ”’ ì„¸ë¶€ìœ„ì¹˜ ì •ë¦¬
            if detail in ("", "ë³´ê´€", f"{floor} ë³´ê´€"):
                detail = ""

            # âœ… íŠ¹ìˆ˜ ìœ„ì¹˜ëŠ” ë‹¨ë… ì²˜ë¦¬
            if floor in ("ì™¸ì£¼", "íê¸°", "ì†Œì§„", "ì°½ê³ "):
                current_loc = floor

            else:
                # ì¼ë°˜ ì¸µ (ì˜ˆ: 4ì¸µ, 5ì¸µ ...)
                if not floor:
                    current_loc = detail or ""
                else:
                    # ì„¸ë¶€ìœ„ì¹˜ì— ì´ë¯¸ '4ì¸µ' ê°™ì€ ê²Œ ë¶™ì–´ ìˆìœ¼ë©´ ì œê±°
                    if detail.startswith(floor):
                        detail = detail[len(floor):].strip()

                    if not detail:
                        detail = "ë³´ê´€"

                    current_loc = f"{floor} {detail}"


            # í†µìˆ˜ëŸ‰ íŒŒì‹±
            n = 0
            s_cnt = norm_str(cnt_raw)
            if s_cnt:
                try:
                    n = int(float(s_cnt))
                except Exception:
                    n = 0

            # ì™¸ì£¼/íê¸°/ì†Œì§„ì¸ë° í†µìˆ˜ëŸ‰ì´ ë¹„ì–´ìˆìœ¼ë©´ 1ê°œë¡œ ê°„ì£¼(ê¸°ì¡´ ê·œì¹™ ìœ ì§€)
            if current_loc in ("ì™¸ì£¼", "íê¸°", "ì†Œì§„") and n <= 0:
                n = 1

            # ìš©ëŸ‰/ìœ„ì¹˜/í†µìˆ˜ëŸ‰ ëª¨ë‘ ì˜ë¯¸ ì—†ìœ¼ë©´ ìŠ¤í‚µ
            cap_empty = (pd.isna(cap) or cap == 0)
            if n <= 0 and cap_empty and not current_loc:
                continue

            if n <= 0:
                continue

            # í†µìˆ˜ëŸ‰ë§Œí¼ í–‰ ìƒì„±
            for _ in range(n):
                rows.append({
                    **base,
                    "í†µë²ˆí˜¸": drum_no,
                    "í†µìš©ëŸ‰": cap,
                    "í˜„ì¬ìœ„ì¹˜": current_loc,
                })

    return pd.DataFrame(rows)

# =========================================================
# ì¶”ì¶œ íƒ­: ì‹œíŠ¸ë³„ë¡œ íŒŒì¼ ë§Œë“¤ê¸° + ZIP ë¬¶ê¸°
# =========================================================
def extract_and_zip(excel_file):
    """
    ë²Œí¬ ê´€ë¦¬ëŒ€ì¥ ì—‘ì…€ ì—…ë¡œë“œ íŒŒì¼ë¡œë¶€í„°:
      1) bulk_drums_extended.csv
      2) ì œì¡°ì‘ì—…ì‹¤ì í˜„í™© â†’ production.xlsx
      3) ì¼ìë³„í†µí•©ì¬ê³ í˜„í™© â†’ stock.xlsx
      4) ì…í•˜í˜„í™© â†’ receive.xlsx
      5) LOG â†’ bulk_move_log.csv (UTF-8)
    ë¥¼ í•˜ë‚˜ì˜ ZIPìœ¼ë¡œ ë¬¶ì–´ BytesIO ë°˜í™˜
    """
    excel_bytes = excel_file.read()

    # 1) bulk_drums_extended.csv (ë©”ì¸ ì‹œíŠ¸ ê¸°ë°˜)
    df_drums = extract_bulk_drums_from_main(excel_bytes)
    drums_buf = BytesIO()
    df_drums.to_csv(drums_buf, index=False, encoding="utf-8-sig")
    drums_bytes = drums_buf.getvalue()

    # 2~4,5ëŠ” pandasë¡œ ê°ê° ì½ì–´ì„œ ë‚´ë³´ë‚´ê¸°
    # ì—¬ëŸ¬ ë²ˆ ì½ì–´ì•¼ í•˜ë¯€ë¡œ BytesIO ìƒˆë¡œ ë§Œë“¤ì–´ ì‚¬ìš©
    excel_buf_for_pd = BytesIO(excel_bytes)

    sheet_names = {
        "ì œì¡°ì‘ì—…ì‹¤ì í˜„í™©": "production.xlsx",
        "ì¼ìë³„í†µí•©ì¬ê³ í˜„í™©": "stock.xlsx",
        "ì…í•˜í˜„í™©": "receive.xlsx",
    }

    xlsx_files = {}
    for sheet, fname in sheet_names.items():
        excel_buf_for_pd.seek(0)
        try:
            df_sheet = pd.read_excel(excel_buf_for_pd, sheet_name=sheet)
        except ValueError:
            # ì‹œíŠ¸ê°€ ì—†ëŠ” ê²½ìš° ìŠ¤í‚µ
            continue

        out_buf = BytesIO()
        # engine='openpyxl'ì€ ê¸°ë³¸ì´ë¼ ìƒëµ ê°€ëŠ¥
        df_sheet.to_excel(out_buf, index=False)
        xlsx_files[fname] = out_buf.getvalue()

    # 5) LOG ì‹œíŠ¸ â†’ bulk_move_log.csv (UTF-8, ID í¬í•¨ í‘œì¤€í™”)
    excel_buf_for_pd.seek(0)
    try:
        df_log = pd.read_excel(excel_buf_for_pd, sheet_name="LOG")

        # ì»¬ëŸ¼ëª… ì •ë¦¬
        df_log.columns = [str(c).strip() for c in df_log.columns]

        # "ì‹œê°„"ì€ ë°˜ë“œì‹œ ìˆì–´ì•¼ ì˜ë¯¸ ìˆìŒ. ì—†ìœ¼ë©´ ê·¸ëŒ€ë¡œ ë‚´ë³´ë‚´ë˜, ì•„ë˜ í‘œì¤€ì»¬ëŸ¼ì€ ë§Œë“¤ ìˆ˜ ìˆëŠ” ë§Œí¼ ë§Œë“ ë‹¤.
        if "ID" not in df_log.columns:
            df_log.insert(1, "ID", "")

        # í‘œì¤€ ì»¬ëŸ¼ ìˆœì„œ ê°•ì œ (ì—†ëŠ” ì»¬ëŸ¼ì€ ë¹ˆ ê°’ìœ¼ë¡œ ìƒì„±)
        std_cols = [
            "ì‹œê°„", "ID", "í’ˆë²ˆ", "í’ˆëª…", "ë¡œíŠ¸ë²ˆí˜¸", "í†µë²ˆí˜¸",
            "ë³€ê²½ ì „ ìš©ëŸ‰", "ë³€ê²½ í›„ ìš©ëŸ‰", "ë³€í™”ëŸ‰",
            "ë³€ê²½ ì „ ìœ„ì¹˜", "ë³€ê²½ í›„ ìœ„ì¹˜",
        ]

        # "í’ˆëª©ì½”ë“œ"ë¡œ ì €ì¥ëœ ê²½ìš°ë„ "í’ˆë²ˆ"ìœ¼ë¡œ ë§ì¶°ì£¼ê¸°
        if "í’ˆë²ˆ" not in df_log.columns and "í’ˆëª©ì½”ë“œ" in df_log.columns:
            df_log["í’ˆë²ˆ"] = df_log["í’ˆëª©ì½”ë“œ"]

        for c in std_cols:
            if c not in df_log.columns:
                df_log[c] = ""

        df_log = df_log[std_cols]

        log_buf = BytesIO()
        df_log.to_csv(log_buf, index=False, encoding="utf-8-sig")
        log_bytes = log_buf.getvalue()
    except ValueError:
        log_bytes = b""

    # ZIP ë¬¶ê¸°
    zip_buf = BytesIO()
    with zipfile.ZipFile(zip_buf, "w", zipfile.ZIP_DEFLATED) as zf:
        zf.writestr("bulk_drums_extended.csv", drums_bytes)

        for fname, data in xlsx_files.items():
            zf.writestr(fname, data)

        zf.writestr("bulk_move_log.csv", log_bytes)

    zip_buf.seek(0)
    return zip_buf


# =========================================================
# Streamlit UI
# =========================================================
def main():
    st.title("ë²Œí¬ ê´€ë¦¬ëŒ€ì¥ ë„ìš°ë¯¸")

    tab_update, tab_extract = st.tabs(["ì—…ë°ì´íŠ¸", "ì¶”ì¶œ"])

    # ---------------------- ì—…ë°ì´íŠ¸ íƒ­ ----------------------
    with tab_update:
        st.subheader("LOG ê¸°ì¤€ ë©”ì¸/LOG ì—…ë°ì´íŠ¸")

        excel_file = st.file_uploader(
            "1) ë²Œí¬ ê´€ë¦¬ëŒ€ì¥ ì—‘ì…€ (.xlsm)", type=["xlsm", "xlsx"], key="upd_excel"
        )
        bulk_log_file = st.file_uploader(
            "2) bulk_move_log.csv", type=["csv"], key="upd_log"
        )
        bulk_ext_file = st.file_uploader(
            "3) bulk_drums_extended.csv", type=["csv"], key="upd_ext"
        )

        if st.button("ë¡œê·¸ ë°˜ì˜ ì‹¤í–‰", key="run_update"):
            if not excel_file or not bulk_log_file or not bulk_ext_file:
                st.error("ì„¸ íŒŒì¼ ëª¨ë‘ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”.")
            else:
                try:
                    updated_bytes, applied_count = process_bulk_log_streamlit(
                        excel_file, bulk_log_file, bulk_ext_file
                    )
                except Exception as e:
                    st.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                else:
                    st.success(f"ì²˜ë¦¬ ì™„ë£Œ! ì‹ ê·œ ë¡œê·¸ {applied_count}ê±´ì´ ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    st.download_button(
                        label="ìˆ˜ì •ëœ ë²Œí¬ ê´€ë¦¬ëŒ€ì¥ ë‹¤ìš´ë¡œë“œ",
                        data=updated_bytes,
                        file_name="ë²Œí¬ ê´€ë¦¬ëŒ€ì¥_ë¡œê·¸ë°˜ì˜.xlsm",
                        mime="application/vnd.ms-excel",
                        key="upd_download",
                    )

    # ---------------------- ì¶”ì¶œ íƒ­ ----------------------
    with tab_extract:
        st.subheader("ë²Œí¬ ê´€ë¦¬ëŒ€ì¥ì—ì„œ ì„¸íŠ¸ íŒŒì¼ ì¶”ì¶œ")

        excel_extract_file = st.file_uploader(
            "ë²Œí¬ ê´€ë¦¬ëŒ€ì¥ ì—‘ì…€ (.xlsm) ì—…ë¡œë“œ", type=["xlsm", "xlsx"], key="ext_excel"
        )

        if st.button("ì„¸íŠ¸ íŒŒì¼ ì¶”ì¶œ", key="run_extract"):
            if not excel_extract_file:
                st.error("ë²Œí¬ ê´€ë¦¬ëŒ€ì¥ ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”.")
            else:
                try:
                    zip_buf = extract_and_zip(excel_extract_file)
                except Exception as e:
                    st.error(f"ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                else:
                    st.success("ì¶”ì¶œ ì™„ë£Œ! ì•„ë˜ ë²„íŠ¼ìœ¼ë¡œ ZIP íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.")
                    st.download_button(
                        label="ì¶”ì¶œ ê²°ê³¼ ZIP ë‹¤ìš´ë¡œë“œ",
                        data=zip_buf.getvalue(),
                        file_name="bulk_bundle_export.zip",
                        mime="application/zip",
                        key="ext_download",
                    )


if __name__ == "__main__":
    main()
